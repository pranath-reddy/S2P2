{"cells":[{"cell_type":"code","execution_count":null,"id":"pRMeb1RXi0Xw","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14512,"status":"ok","timestamp":1722181011130,"user":{"displayName":"Pranath Reddy Kumbam","userId":"13245202322626445782"},"user_tz":240},"id":"pRMeb1RXi0Xw","outputId":"ec2f788a-775e-4dc4-aae4-e08532798014"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"pRlBaQW9i0cA","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1722181011131,"user":{"displayName":"Pranath Reddy Kumbam","userId":"13245202322626445782"},"user_tz":240},"id":"pRlBaQW9i0cA","outputId":"038b6356-c166-4e64-dded-297779086be4"},"outputs":[],"source":["cd drive/My \\Drive/NLP"]},{"cell_type":"code","execution_count":null,"id":"tc1Fh_rKz96-","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":125213,"status":"ok","timestamp":1722181136341,"user":{"displayName":"Pranath Reddy Kumbam","userId":"13245202322626445782"},"user_tz":240},"id":"tc1Fh_rKz96-","outputId":"e5ac9bee-b46f-4a1e-e4a2-563a0efcc832"},"outputs":[],"source":["!pip install textattack==0.3.7"]},{"cell_type":"code","execution_count":null,"id":"cesQh3Ds29H9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10131,"status":"ok","timestamp":1722181146468,"user":{"displayName":"Pranath Reddy Kumbam","userId":"13245202322626445782"},"user_tz":240},"id":"cesQh3Ds29H9","outputId":"6217d3bc-baff-4609-b74c-b488eca5a137"},"outputs":[],"source":["!pip install lime"]},{"cell_type":"code","execution_count":null,"id":"-8vwWnh5_9ry","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13908,"status":"ok","timestamp":1722181160565,"user":{"displayName":"Pranath Reddy Kumbam","userId":"13245202322626445782"},"user_tz":240},"id":"-8vwWnh5_9ry","outputId":"76634a9a-9d3b-4849-ce4e-36ef08280f86"},"outputs":[],"source":["!pip install python-Levenshtein"]},{"cell_type":"code","execution_count":null,"id":"86980d01-4250-4b43-b306-6f7587b0edc8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31286,"status":"ok","timestamp":1722181191834,"user":{"displayName":"Pranath Reddy Kumbam","userId":"13245202322626445782"},"user_tz":240},"id":"86980d01-4250-4b43-b306-6f7587b0edc8","outputId":"853e1295-bd54-4232-ecc6-c7c7c57204f0"},"outputs":[],"source":["# Load libraries\n","import pandas as pd\n","import numpy as np\n","import nltk\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n","from lime.lime_text import LimeTextExplainer\n","from nltk.corpus import stopwords, wordnet\n","from nltk.stem import WordNetLemmatizer\n","from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n","import random\n","import Levenshtein\n","import transformers\n","import textattack\n","from textattack.datasets import Dataset\n","from datasets import load_dataset\n","from transformers import GPT2Tokenizer\n","from textattack.models.wrappers import ModelWrapper\n","from textattack.models.wrappers import HuggingFaceModelWrapper\n","from textattack import Attack\n","from textattack.transformations import WordSwapEmbedding\n","from textattack.search_methods import GreedyWordSwapWIR\n","from textattack.constraints.pre_transformation import RepeatModification, StopwordModification\n","from textattack.constraints.semantics import WordEmbeddingDistance\n","\n","nltk.download('omw-1.4')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":null,"id":"jYQfKuD9b8jp","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45333,"status":"ok","timestamp":1722181237151,"user":{"displayName":"Pranath Reddy Kumbam","userId":"13245202322626445782"},"user_tz":240},"id":"jYQfKuD9b8jp","outputId":"076e2e34-4e7c-49ff-957f-8ef11afcbc31"},"outputs":[],"source":["# Load the dataset\n","df = pd.read_csv('./Data/KaggleData.csv')\n","\n","# Convert to lowercase, remove punctuation, extra spaces, URLs, mentions, and hashtags\n","df['tweet'] = df['tweet'].str.lower().replace(r'[^\\w\\s]', '', regex=True).replace(' {2,}', ' ', regex=True).replace('\"', '')\n","df['tweet'] = df['tweet'].replace(r'http\\S+|www.\\S+|@\\w+|#\\w+', '', regex=True)\n","\n","# Tokenization\n","nltk.download('punkt')\n","df['tweet'] = df['tweet'].apply(nltk.word_tokenize)\n","\n","# Lemmatization\n","nltk.download('wordnet')\n","lemmatizer = WordNetLemmatizer()\n","df['tweet'] = df['tweet'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n","\n","# Removing stop-words\n","nltk.download('stopwords')\n","stop_words = set(stopwords.words('english'))\n","df['tweet'] = df['tweet'].apply(lambda x: ' '.join([word for word in x if word not in stop_words]))\n","\n","# Create a custom dataset class\n","class TextDataset(Dataset):\n","    def __init__(self, texts, labels):\n","        self.texts = texts\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        return self.texts[idx], self.labels[idx]\n","\n","# Encode the labels\n","# 0 - hate speech, 1 - offensive language, 2 - neither as positive or negative\n","label_encoder = LabelEncoder()\n","y = label_encoder.fit_transform(df['class'])\n","\n","# Splitting the Data using Stratified split\n","X_train, X_test, y_train, y_test = train_test_split(df['tweet'], y, test_size=0.3, stratify=y, random_state=42)\n","\n","# Tokenize and pad the input sequences\n","def tokenize_and_pad(texts, maxlen=100):\n","    tokenized_texts = [nltk.word_tokenize(text) for text in texts]\n","    return pad_sequence([torch.tensor([word2index[word] for word in text if word in word2index][:maxlen]) for text in tokenized_texts], batch_first=True, padding_value=len(word2index))\n","\n","word2index = {word: i for i, word in enumerate(set(df['tweet'].str.cat(sep=' ').split()), 1)}\n","X_train = tokenize_and_pad(X_train)\n","X_test = tokenize_and_pad(X_test)\n","\n","# Create PyTorch Datasets and DataLoaders\n","train_dataset = TextDataset(X_train, y_train)\n","test_dataset = TextDataset(X_test, y_test)\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32)\n","\n","# Create a PyTorch LSTM model\n","class LSTMBaseline(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, num_classes)\n","\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        packed_output, (hidden, cell) = self.lstm(x)\n","        x = self.fc(hidden[-1])\n","        return x\n","\n","# Initialize the model, optimizer, and loss function\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = LSTMBaseline(len(word2index) + 1, 50, 100, len(set(y))).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Train the model\n","epochs = 10\n","for epoch in range(epochs):\n","    model.train()\n","    epoch_loss = 0\n","\n","    for texts, labels in train_loader:\n","        texts, labels = texts.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(texts)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss / len(train_loader)}\")\n","\n","    # Save Model\n","    torch.save(model, './Weights/KaggleLSTM.pth')\n","\n","model = torch.load('./Weights/KaggleLSTM.pth')\n","\n","# Test the model and collect predictions and true labels\n","model.eval()\n","predictions = []\n","true_labels = []\n","\n","with torch.no_grad():\n","    for texts, labels in test_loader:\n","        texts, labels = texts.to(device), labels.to(device)\n","        outputs = model(texts)\n","        _, predicted = torch.max(outputs, 1)\n","        predictions.extend(predicted.cpu().numpy())\n","        true_labels.extend(labels.cpu().numpy())\n","\n","# Calculate accuracy, precision, recall, F1-score, and confusion matrix\n","accuracy = np.mean(np.array(predictions) == np.array(true_labels))\n","precision, recall, f1_score, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n","conf_mat = confusion_matrix(true_labels, predictions)\n","\n","print(\"Accuracy: \", accuracy)\n","print(\"Precision: \", precision)\n","print(\"Recall: \", recall)\n","print(\"F1-score: \", f1_score)\n","print(\"Confusion Matrix:\\n\", conf_mat)"]},{"cell_type":"code","execution_count":null,"id":"hKt0Gow7-U80","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1722181237151,"user":{"displayName":"Pranath Reddy Kumbam","userId":"13245202322626445782"},"user_tz":240},"id":"hKt0Gow7-U80","outputId":"ea2dbd31-6b4d-4e87-9658-6264de5f23cc"},"outputs":[],"source":["# Wrapper for the TextCNN model\n","class LSTMBaselineWrapper:\n","    def __init__(self, model):\n","        self.model = model\n","\n","    def __call__(self, text_input_list):\n","        preds = []\n","        for text in text_input_list:\n","            input_tensor = tokenize_and_pad([text]).long()\n","            output = self.model(input_tensor.to(device))\n","            pred = torch.softmax(output, dim=1).squeeze().tolist()\n","            preds.append(pred)\n","        return np.array(preds)\n","\n","def tokenize_and_pad(text_list):\n","    max_length = 50\n","    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n","    tokens = [tokenizer.tokenize(text)[:max_length] for text in text_list]\n","    token_indices = np.zeros((len(tokens), max_length), dtype=int)\n","    for i, tweet in enumerate(tokens):\n","        for j, word in enumerate(tweet):\n","            if word in word2index:\n","                token_indices[i, j] = word2index[word]\n","    return torch.tensor(token_indices)\n","\n","wrapped_model = LSTMBaselineWrapper(model)\n","class_names = ['hate_speech', 'offensive_language', 'neither']\n","\n","# Explainability\n","def lime_analysis(text, wrapped_model, class_names):\n","    explainer = LimeTextExplainer(class_names=class_names)\n","    exp = explainer.explain_instance(text, wrapped_model, num_features=10, num_samples=2)\n","    return exp.as_list()\n","\n","df['tweet'] = df['tweet'].apply(lambda x: ' '.join(x))\n","text_to_explain = random.choice(df['tweet'])\n","print(\"Text to explain:\", text_to_explain)\n","lime_results = lime_analysis(text_to_explain, wrapped_model, class_names)\n","print(\"LIME analysis results:\")\n","print(lime_results)\n","\n","def calculate_doe(lime_results):\n","    feature_scores = [abs(score) for _, score in lime_results]\n","    std_dev = np.std(feature_scores)\n","    significant_features = len([score for score in feature_scores if score > std_dev])\n","    return significant_features / len(feature_scores)\n","\n","doe = calculate_doe(lime_results)\n","print(\"Degree of Explainability (DoE):\", doe)"]},{"cell_type":"code","execution_count":null,"id":"GcU_3HcBjZyl","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":202,"status":"ok","timestamp":1722181237351,"user":{"displayName":"Pranath Reddy Kumbam","userId":"13245202322626445782"},"user_tz":240},"id":"GcU_3HcBjZyl","outputId":"44a58dbc-d08d-4d6f-b493-6fd73c8c3b87"},"outputs":[],"source":["# Define number of samples for analysis\n","num_sam = 20\n","\n","# Load dataset\n","def load_custom_dataset(path):\n","    df = pd.read_csv(path)\n","    df = df.dropna(subset=['tweet', 'class'])\n","    return df\n","\n","# LIME Analysis\n","def lime_analysis(text, wrapped_model, class_names):\n","    explainer = LimeTextExplainer(class_names=class_names)\n","    exp = explainer.explain_instance(text, wrapped_model, num_features=10, num_samples=2)\n","    return exp.as_list()\n","\n","# Calculate Degree of Explainability (DoE)\n","def calculate_doe(lime_results):\n","    feature_scores = [abs(score) for _, score in lime_results]\n","    std_dev = np.std(feature_scores)\n","    significant_features = len([score for score in feature_scores if score > std_dev])\n","    return significant_features / len(feature_scores)\n","\n","# Calculate average DoE for Multiple samples\n","def calculate_average_doe(df, wrapped_model, class_names, samples=num_sam):\n","    doe_values = []\n","    sample_texts = random.sample(list(df['tweet']), samples)\n","    for text in sample_texts:\n","        lime_results = lime_analysis(text, wrapped_model, class_names)\n","        doe = calculate_doe(lime_results)\n","        doe_values.append(doe)\n","    average_doe = np.mean(doe_values)\n","    return average_doe\n","\n","# Path to the dataset\n","test_data_path = \"./Data/KaggleData.csv\"\n","df = load_custom_dataset(test_data_path)\n","\n","# Assuming wrapped_model and class_names are defined elsewhere\n","class_names = ['Hate speech', 'Offensive language', 'Neutral']\n","\n","# Calculate and print average DoE\n","average_doe = calculate_average_doe(df, wrapped_model, class_names)\n","print(f\"Average Degree of Explainability (DoE) for {num_sam} samples:\", average_doe)"]},{"cell_type":"code","execution_count":null,"id":"I_7o9CAuCKGG","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25863,"status":"ok","timestamp":1722181263213,"user":{"displayName":"Pranath Reddy Kumbam","userId":"13245202322626445782"},"user_tz":240},"id":"I_7o9CAuCKGG","outputId":"245f9806-da50-46d6-fcf8-2c4f3b2927b4"},"outputs":[],"source":["import numpy as np\n","from lime.lime_text import LimeTextExplainer\n","from nltk.corpus import wordnet\n","import random\n","import torch\n","\n","# Function to get synonyms for a word\n","def get_synonym(word):\n","    synonyms = set()\n","    for syn in wordnet.synsets(word):\n","        for lemma in syn.lemmas():\n","            if lemma.name() != word:\n","                synonyms.add(lemma.name().replace('_', ' '))\n","    return random.choice(list(synonyms)) if synonyms else word\n","\n","# Function to generate adversarial example using LIME\n","def generate_adversarial_example(text, predictor, explainer, num_features=2):\n","    exp = explainer.explain_instance(text, predictor, num_features=num_features)\n","    words = text.split()\n","    for feature, _ in exp.as_list()[:num_features]:\n","        if feature in words:\n","            idx = words.index(feature)\n","            words[idx] = get_synonym(words[idx])\n","    return ' '.join(words)\n","\n","# Wrapper for model prediction\n","def model_predict(texts):\n","    # Convert texts to indices\n","    indexed_texts = [[word2index.get(word, len(word2index)) for word in text.split()] for text in texts]\n","    # Pad sequences\n","    padded_texts = pad_sequence([torch.tensor(text) for text in indexed_texts], batch_first=True, padding_value=len(word2index))\n","    padded_texts = padded_texts.to(device)\n","    with torch.no_grad():\n","        outputs = model(padded_texts)\n","    return torch.softmax(outputs, dim=1).cpu().numpy()\n","\n","# LIME-based adversarial attack\n","def lime_based_attack(dataset, samples=num_sam):\n","    correct_before_attack = 0\n","    correct_after_attack = 0\n","    total_samples = 0\n","\n","    explainer = LimeTextExplainer(class_names=['hate speech', 'offensive language', 'neither'])\n","\n","    for texts, labels in dataset:\n","        for text, label in zip(texts, labels):\n","            if total_samples >= samples:\n","                return total_samples, correct_before_attack, correct_after_attack\n","\n","            # Convert tensor to string\n","            text = ' '.join([list(word2index.keys())[list(word2index.values()).index(i)] for i in text if i < len(word2index)])\n","\n","            # Original prediction\n","            original_pred = model_predict([text])[0].argmax()\n","            if original_pred == label:\n","                correct_before_attack += 1\n","\n","            # Generate adversarial example\n","            adv_text = generate_adversarial_example(text, model_predict, explainer)\n","            adv_pred = model_predict([adv_text])[0].argmax()\n","\n","            if adv_pred == label:\n","                correct_after_attack += 1\n","\n","            total_samples += 1\n","\n","    return total_samples, correct_before_attack, correct_after_attack\n","\n","# Perform the attack\n","total_samples, correct_before_attack, correct_after_attack = lime_based_attack(train_loader)\n","\n","# Calculate metrics\n","accuracy_before_attack = correct_before_attack / total_samples\n","accuracy_after_attack = correct_after_attack / total_samples\n","adv_rob = accuracy_after_attack / accuracy_before_attack if accuracy_before_attack > 0 else 0\n","\n","attack_resilience = adv_rob / average_doe if average_doe > 0 else 0\n","\n","# Print results\n","print(\"LIME-based adversarial attack results:\")\n","print(f\"Total samples: {total_samples}\")\n","print(f\"Correct before attack: {correct_before_attack}\")\n","print(f\"Correct after attack: {correct_after_attack}\")\n","print(f\"Accuracy before attack: {accuracy_before_attack}\")\n","print(f\"Accuracy after attack: {accuracy_after_attack}\")\n","print(\"\")\n","print(\"Results: \")\n","print(\"Adversarial Robustness (AdvRob):\", adv_rob)\n","print(\"Attack Resilience (Ar):\", attack_resilience)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":5}
