{"cells":[{"cell_type":"code","execution_count":null,"id":"pRMeb1RXi0Xw","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17011,"status":"ok","timestamp":1722207708406,"user":{"displayName":"Pranath Reddy Kumbam","userId":"13245202322626445782"},"user_tz":240},"id":"pRMeb1RXi0Xw","outputId":"21d16fef-bd65-490a-b5e6-07a46f17b478"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"pRlBaQW9i0cA","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1722207708407,"user":{"displayName":"Pranath Reddy Kumbam","userId":"13245202322626445782"},"user_tz":240},"id":"pRlBaQW9i0cA","outputId":"eb205dca-5ad6-411b-c0c7-0886e712b75d"},"outputs":[],"source":["cd drive/My \\Drive/NLP"]},{"cell_type":"code","execution_count":null,"id":"tc1Fh_rKz96-","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":107111,"status":"ok","timestamp":1722207815514,"user":{"displayName":"Pranath Reddy Kumbam","userId":"13245202322626445782"},"user_tz":240},"id":"tc1Fh_rKz96-","outputId":"f4ded324-f949-4044-90f9-d5382756a9c3"},"outputs":[],"source":["!pip install textattack==0.3.7"]},{"cell_type":"code","execution_count":null,"id":"cesQh3Ds29H9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9236,"status":"ok","timestamp":1722207824743,"user":{"displayName":"Pranath Reddy Kumbam","userId":"13245202322626445782"},"user_tz":240},"id":"cesQh3Ds29H9","outputId":"9213fef7-20b3-45fd-a764-044c37995c01"},"outputs":[],"source":["!pip install lime"]},{"cell_type":"code","execution_count":null,"id":"-8vwWnh5_9ry","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14662,"status":"ok","timestamp":1722207839386,"user":{"displayName":"Pranath Reddy Kumbam","userId":"13245202322626445782"},"user_tz":240},"id":"-8vwWnh5_9ry","outputId":"56e9f847-3a69-4a10-df7b-fd4392abf3ed"},"outputs":[],"source":["pip install -U datasets"]},{"cell_type":"code","execution_count":null,"id":"86980d01-4250-4b43-b306-6f7587b0edc8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30113,"status":"ok","timestamp":1722207869479,"user":{"displayName":"Pranath Reddy Kumbam","userId":"13245202322626445782"},"user_tz":240},"id":"86980d01-4250-4b43-b306-6f7587b0edc8","outputId":"b53056ec-f468-45c3-ea0f-499c0e1cf73d"},"outputs":[],"source":["# Load libraries\n","import pandas as pd\n","import numpy as np\n","import nltk\n","import torch\n","import torch.nn as nn\n","import datasets\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n","from lime.lime_text import LimeTextExplainer\n","from nltk.corpus import stopwords, wordnet\n","from nltk.stem import WordNetLemmatizer\n","from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n","import random\n","import transformers\n","import textattack\n","from textattack.datasets import Dataset\n","from datasets import load_dataset\n","from transformers import GPT2Tokenizer\n","from textattack.models.wrappers import ModelWrapper\n","from textattack.models.wrappers import HuggingFaceModelWrapper\n","from textattack import Attack\n","from textattack.transformations import WordSwapEmbedding\n","from textattack.search_methods import GreedyWordSwapWIR\n","from textattack.constraints.pre_transformation import RepeatModification, StopwordModification\n","from textattack.constraints.semantics import WordEmbeddingDistance\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n","import datasets\n","\n","nltk.download('omw-1.4')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":null,"id":"jYQfKuD9b8jp","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":631,"referenced_widgets":["c98391c7a6734a9bb3e555d92885ba65","5cff6ae8b97e4bdd93db766971ba8c91","c8622fdd4fdc499291dcb173f911b2f2","da16f6388eef4b6c85fa170832b53844","dfdc3a8e0b94402893d20ec1beccaa58","f6df980302c8485e81f4a90c734c697d","6a25f4b3c79441a2a31003ab6e442d14","1ed96ec59efa41d6988a5373d5668260","30562168fc3c4530b8de144cc7a8dd8f","aa057e6829ee4b62aa8cd18e233447de","ae5b98d9ad6644588e00034dd8abf9d9","9df5ed97bec04c16be0ddd5a622e3ccb","c6b3426a45484f21bf9b235a59e29e66","f9a28d633ee54c26bb76a83de9a6478c","4bda381c88034af99fb290029b3119a1","ddec23692f634c34964d1182d2b7c524","83aa3174cb6f4bcea161a4cc9f23a95c","8aaeafb316d04bb3a66e4989c8f4dee0","d2ec88b9df6947418107d1fae977d025","11dd7300274a4d2e82e4f28c7f6d00d9","8286c0cf20914a8ca91e9c89ea857a77","23707201453548d2881bae6c6d257535","8a7388bed3fe4784bd276474ff79f72b","4c32ed0094ce4ecb8c4e42d34c7b07cd","2fdeeac3ba9e4be9a5e45e4e010f714b","bc1b6850eb6343f39dc61b2279c337b3","cc005186ca8941868db0c688d919c9ba","3ba22953353c46e3a41e73c372efa5b1","0b2abe3b0fc9472ea95866f8ab8398b1","6f27e586fa95454fa2746a31c9782d2b","8607bb33ce3845dd855d47d65044bc3c","0b256b58cdbc4cb9afaf9f1cbd6d8c25","de9e0fd641a34bf0a9eaa611fdf8afd8"]},"executionInfo":{"elapsed":1695480,"status":"ok","timestamp":1722209564952,"user":{"displayName":"Pranath Reddy Kumbam","userId":"13245202322626445782"},"user_tz":240},"id":"jYQfKuD9b8jp","outputId":"b536bb00-1af5-4cc8-aa0d-59944a1ae35b"},"outputs":[],"source":["torch.manual_seed(42)\n","np.random.seed(42)\n","\n","# Load the dataset\n","dataset = datasets.load_dataset('ucberkeley-dlab/measuring-hate-speech', 'default')\n","df = dataset['train'].to_pandas()\n","df.rename(columns={'text': 'tweet', 'hate_speech_score': 'class'}, inplace=True)\n","df['binary_class'] = df['class'] > 0.5\n","\n","# Convert to lowercase, remove punctuation, extra spaces, URLs, mentions, and hashtags\n","df['tweet'] = df['tweet'].str.lower().replace(r'[^\\w\\s]', '', regex=True).replace(' {2,}', ' ', regex=True).replace('\"', '')\n","df['tweet'] = df['tweet'].replace(r'http\\S+|www.\\S+|@\\w+|#\\w+', '', regex=True)\n","\n","# Tokenization\n","nltk.download('punkt')\n","df['tweet'] = df['tweet'].apply(nltk.word_tokenize)\n","\n","# Lemmatization\n","nltk.download('wordnet')\n","lemmatizer = WordNetLemmatizer()\n","df['tweet'] = df['tweet'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n","\n","# Removing stop-words\n","nltk.download('stopwords')\n","stop_words = set(stopwords.words('english'))\n","df['tweet'] = df['tweet'].apply(lambda x: ' '.join([word for word in x if word not in stop_words]))\n","\n","# Prepare data for DataLoader\n","max_length = 50\n","tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n","df['tweet'] = df['tweet'].apply(lambda x: tokenizer.tokenize(x)[:max_length])\n","\n","# Create word2index dictionary\n","word2index = {}\n","for tweet in df['tweet']:\n","    for word in tweet:\n","        if word not in word2index:\n","            word2index[word] = len(word2index)\n","\n","# Convert words to indices and pad sequences\n","input_data = np.zeros((len(df['tweet']), max_length), dtype=int)\n","for i, tweet in enumerate(df['tweet']):\n","    for j, word in enumerate(tweet):\n","        input_data[i, j] = word2index[word]\n","\n","# Encode labels\n","le = LabelEncoder()\n","y = le.fit_transform(df['binary_class'])\n","\n","# Split the data\n","X_train, X_test, y_train, y_test = train_test_split(input_data, y, test_size=0.3, stratify=y, random_state=42)\n","\n","class TextDataset(Dataset):\n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(self.X[idx], dtype=torch.long), torch.tensor(self.y[idx], dtype=torch.long)\n","\n","train_dataset = TextDataset(X_train, y_train)\n","test_dataset = TextDataset(X_test, y_test)\n","\n","batch_size = 64\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","class TextCNN(nn.Module):\n","    def __init__(self, vocab_size, embed_dim, num_classes):\n","        super(TextCNN, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embed_dim)\n","        self.conv1 = nn.Conv2d(1, 100, (3, embed_dim))\n","        self.conv2 = nn.Conv2d(1, 100, (4, embed_dim))\n","        self.conv3 = nn.Conv2d(1, 100, (5, embed_dim))\n","        self.fc = nn.Linear(300, num_classes)\n","\n","    def forward(self, x):\n","        x = self.embedding(x).unsqueeze(1)\n","        x1 = F.relu(self.conv1(x)).squeeze(3)\n","        x2 = F.relu(self.conv2(x)).squeeze(3)\n","        x3 = F.relu(self.conv3(x)).squeeze(3)\n","        x1 = F.max_pool1d(x1, x1.size(2)).squeeze(2)\n","        x2 = F.max_pool1d(x2, x2.size(2)).squeeze(2)\n","        x3 = F.max_pool1d(x3, x3.size(2)).squeeze(2)\n","        x = torch.cat((x1, x2, x3), 1)\n","        x = self.fc(x)\n","        return x\n","\n","vocab_size = len(word2index)\n","embed_dim = 100\n","num_classes = 2\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = TextCNN(vocab_size, embed_dim, num_classes).to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Train the model\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for inputs, labels in train_dataloader:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_dataloader)}\")\n","\n","    # Save Model\n","    torch.save(model, './Weights/HuggingFaceCNN.pth')\n","\n","model = torch.load('./Weights/HuggingFaceCNN.pth')\n","\n","# Test the model\n","# Prepare true labels and predictions for metrics calculation\n","true_labels = []\n","predictions = []\n","\n","with torch.no_grad():\n","    for inputs, labels in test_dataloader:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        true_labels.extend(labels.cpu().numpy())\n","        predictions.extend(predicted.cpu().numpy())\n","\n","# Calculate accuracy, precision, recall, F1-score, and confusion matrix\n","accuracy = accuracy_score(true_labels, predictions)\n","precision, recall, f1_score, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n","conf_mat = confusion_matrix(true_labels, predictions)\n","\n","print(\"Accuracy: \", accuracy)\n","print(\"Precision: \", precision)\n","print(\"Recall: \", recall)\n","print(\"F1-score: \", f1_score)\n","print(\"Confusion Matrix:\\n\", conf_mat)"]},{"cell_type":"code","execution_count":null,"id":"hKt0Gow7-U80","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":347,"status":"ok","timestamp":1722209565296,"user":{"displayName":"Pranath Reddy Kumbam","userId":"13245202322626445782"},"user_tz":240},"id":"hKt0Gow7-U80","outputId":"dcaf5cb2-6084-4b85-b325-3616195789d5"},"outputs":[],"source":["# Wrapper for the TextCNN model\n","class LSTMBaselineWrapper:\n","    def __init__(self, model):\n","        self.model = model\n","\n","    def __call__(self, text_input_list):\n","        preds = []\n","        for text in text_input_list:\n","            input_tensor = tokenize_and_pad([text]).long()\n","            output = self.model(input_tensor.to(device))\n","            pred = torch.softmax(output, dim=1).squeeze().tolist()\n","            preds.append(pred)\n","        return np.array(preds)\n","\n","def tokenize_and_pad(text_list):\n","    max_length = 50\n","    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n","    tokens = [tokenizer.tokenize(text)[:max_length] for text in text_list]\n","    token_indices = np.zeros((len(tokens), max_length), dtype=int)\n","    for i, tweet in enumerate(tokens):\n","        for j, word in enumerate(tweet):\n","            if word in word2index:\n","                token_indices[i, j] = word2index[word]\n","    return torch.tensor(token_indices)\n","\n","wrapped_model = LSTMBaselineWrapper(model)\n","class_names = ['hate_speech', 'offensive_language', 'neither']\n","\n","# Explainability\n","def lime_analysis(text, wrapped_model, class_names):\n","    explainer = LimeTextExplainer(class_names=class_names)\n","    exp = explainer.explain_instance(text, wrapped_model, num_features=10, num_samples=2)\n","    return exp.as_list()\n","\n","df['tweet'] = df['tweet'].apply(lambda x: ' '.join(x))\n","text_to_explain = random.choice(df['tweet'])\n","print(\"Text to explain:\", text_to_explain)\n","lime_results = lime_analysis(text_to_explain, wrapped_model, class_names)\n","print(\"LIME analysis results:\")\n","print(lime_results)\n","\n","def calculate_doe(lime_results):\n","    feature_scores = [abs(score) for _, score in lime_results]\n","    std_dev = np.std(feature_scores)\n","    significant_features = len([score for score in feature_scores if score > std_dev])\n","    return significant_features / len(feature_scores)\n","\n","doe = calculate_doe(lime_results)\n","print(\"Degree of Explainability (DoE):\", doe)"]},{"cell_type":"code","execution_count":null,"id":"GcU_3HcBjZyl","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1722209565296,"user":{"displayName":"Pranath Reddy Kumbam","userId":"13245202322626445782"},"user_tz":240},"id":"GcU_3HcBjZyl","outputId":"625a4b1e-6dd1-45bf-c4f3-cf31d956e2d7"},"outputs":[],"source":["# Define number of samples for analysis\n","num_sam = 20\n","\n","# Load dataset\n","def load_custom_dataset(path):\n","    df = pd.read_csv(path)\n","    df = df.dropna(subset=['tweet', 'class'])\n","    return df\n","\n","# LIME Analysis\n","def lime_analysis(text, wrapped_model, class_names):\n","    explainer = LimeTextExplainer(class_names=class_names)\n","    exp = explainer.explain_instance(text, wrapped_model, num_features=10, num_samples=2)\n","    return exp.as_list()\n","\n","# Calculate Degree of Explainability (DoE)\n","def calculate_doe(lime_results):\n","    feature_scores = [abs(score) for _, score in lime_results]\n","    std_dev = np.std(feature_scores)\n","    significant_features = len([score for score in feature_scores if score > std_dev])\n","    return significant_features / len(feature_scores)\n","\n","# Calculate average DoE for Multiple samples\n","def calculate_average_doe(df, wrapped_model, class_names, samples=num_sam):\n","    doe_values = []\n","    sample_texts = random.sample(list(df['tweet']), samples)\n","    for text in sample_texts:\n","        lime_results = lime_analysis(text, wrapped_model, class_names)\n","        doe = calculate_doe(lime_results)\n","        doe_values.append(doe)\n","    average_doe = np.mean(doe_values)\n","    return average_doe\n","\n","# Assuming wrapped_model and class_names are defined elsewhere\n","class_names = ['Hate speech', 'Offensive language', 'Neutral']\n","\n","# Calculate and print average DoE\n","average_doe = calculate_average_doe(df, wrapped_model, class_names)\n","print(f\"Average Degree of Explainability (DoE) for {num_sam} samples:\", average_doe)"]},{"cell_type":"code","execution_count":null,"id":"I_7o9CAuCKGG","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12459,"status":"ok","timestamp":1722209577751,"user":{"displayName":"Pranath Reddy Kumbam","userId":"13245202322626445782"},"user_tz":240},"id":"I_7o9CAuCKGG","outputId":"80c95423-d492-4fa7-8cf2-53e7cc1c8e9d"},"outputs":[],"source":["import numpy as np\n","from lime.lime_text import LimeTextExplainer\n","from nltk.corpus import wordnet\n","import random\n","import torch\n","import torch.nn.functional as F\n","\n","# Function to get synonyms for a word\n","def get_synonym(word):\n","    synonyms = set()\n","    for syn in wordnet.synsets(word):\n","        for lemma in syn.lemmas():\n","            if lemma.name() != word:\n","                synonyms.add(lemma.name().replace('_', ' '))\n","    return random.choice(list(synonyms)) if synonyms else word\n","\n","# Function to generate adversarial example using LIME\n","def generate_adversarial_example(text, predictor, explainer, num_features=2):\n","    exp = explainer.explain_instance(text, predictor, num_features=num_features)\n","    words = text.split()\n","    for feature, _ in exp.as_list()[:num_features]:\n","        if feature in words:\n","            idx = words.index(feature)\n","            words[idx] = get_synonym(words[idx])\n","    return ' '.join(words)\n","\n","# Wrapper for model prediction\n","def model_predict(texts):\n","    model.eval()\n","    indexed_texts = [[word2index.get(word, len(word2index)-1) for word in text.split()] for text in texts]\n","    padded_texts = torch.nn.utils.rnn.pad_sequence([torch.tensor(text) for text in indexed_texts], batch_first=True, padding_value=0)\n","    padded_texts = padded_texts.to(device)\n","    with torch.no_grad():\n","        outputs = model(padded_texts.long())\n","    return F.softmax(outputs, dim=1).cpu().numpy()\n","\n","# LIME-based adversarial attack\n","def lime_based_attack(dataset, samples=num_sam):\n","    correct_before_attack = 0\n","    correct_after_attack = 0\n","    total_samples = 0\n","\n","    explainer = LimeTextExplainer(class_names=['hate speech', 'offensive language', 'neither'])\n","\n","    for inputs, labels in dataset:\n","        for input_tensor, label in zip(inputs, labels):\n","            if total_samples >= samples:\n","                return total_samples, correct_before_attack, correct_after_attack\n","\n","            # Convert tensor to string\n","            text = ' '.join([list(word2index.keys())[i] for i in input_tensor.tolist() if i < len(word2index)])\n","\n","            # Original prediction\n","            original_pred = model_predict([text])[0].argmax()\n","            if original_pred == label:\n","                correct_before_attack += 1\n","\n","            # Generate adversarial example\n","            adv_text = generate_adversarial_example(text, model_predict, explainer)\n","            adv_pred = model_predict([adv_text])[0].argmax()\n","\n","            if adv_pred == label:\n","                correct_after_attack += 1\n","\n","            total_samples += 1\n","\n","    return total_samples, correct_before_attack, correct_after_attack\n","\n","# Perform the attack\n","total_samples, correct_before_attack, correct_after_attack = lime_based_attack(train_dataloader)\n","\n","# Calculate metrics\n","accuracy_before_attack = correct_before_attack / total_samples\n","accuracy_after_attack = correct_after_attack / total_samples\n","adv_rob = accuracy_after_attack / accuracy_before_attack if accuracy_before_attack > 0 else 0\n","\n","attack_resilience = adv_rob / average_doe if average_doe > 0 else 0\n","\n","# Print results\n","print(\"LIME-based adversarial attack results:\")\n","print(f\"Total samples: {total_samples}\")\n","print(f\"Correct before attack: {correct_before_attack}\")\n","print(f\"Correct after attack: {correct_after_attack}\")\n","print(f\"Accuracy before attack: {accuracy_before_attack}\")\n","print(f\"Accuracy after attack: {accuracy_after_attack}\")\n","print(\"\")\n","print(\"Results: \")\n","print(\"Adversarial Robustness (AdvRob):\", adv_rob)\n","print(\"Attack Resilience (Ar):\", attack_resilience)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0b256b58cdbc4cb9afaf9f1cbd6d8c25":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b2abe3b0fc9472ea95866f8ab8398b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11dd7300274a4d2e82e4f28c7f6d00d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ed96ec59efa41d6988a5373d5668260":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23707201453548d2881bae6c6d257535":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fdeeac3ba9e4be9a5e45e4e010f714b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f27e586fa95454fa2746a31c9782d2b","max":135556,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8607bb33ce3845dd855d47d65044bc3c","value":135556}},"30562168fc3c4530b8de144cc7a8dd8f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ba22953353c46e3a41e73c372efa5b1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bda381c88034af99fb290029b3119a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8286c0cf20914a8ca91e9c89ea857a77","placeholder":"​","style":"IPY_MODEL_23707201453548d2881bae6c6d257535","value":" 14.1M/14.1M [00:01&lt;00:00, 6.86MB/s]"}},"4c32ed0094ce4ecb8c4e42d34c7b07cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ba22953353c46e3a41e73c372efa5b1","placeholder":"​","style":"IPY_MODEL_0b2abe3b0fc9472ea95866f8ab8398b1","value":"Generating train split: 100%"}},"5cff6ae8b97e4bdd93db766971ba8c91":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6df980302c8485e81f4a90c734c697d","placeholder":"​","style":"IPY_MODEL_6a25f4b3c79441a2a31003ab6e442d14","value":"Downloading readme: 100%"}},"6a25f4b3c79441a2a31003ab6e442d14":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f27e586fa95454fa2746a31c9782d2b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8286c0cf20914a8ca91e9c89ea857a77":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83aa3174cb6f4bcea161a4cc9f23a95c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8607bb33ce3845dd855d47d65044bc3c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a7388bed3fe4784bd276474ff79f72b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4c32ed0094ce4ecb8c4e42d34c7b07cd","IPY_MODEL_2fdeeac3ba9e4be9a5e45e4e010f714b","IPY_MODEL_bc1b6850eb6343f39dc61b2279c337b3"],"layout":"IPY_MODEL_cc005186ca8941868db0c688d919c9ba"}},"8aaeafb316d04bb3a66e4989c8f4dee0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9df5ed97bec04c16be0ddd5a622e3ccb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c6b3426a45484f21bf9b235a59e29e66","IPY_MODEL_f9a28d633ee54c26bb76a83de9a6478c","IPY_MODEL_4bda381c88034af99fb290029b3119a1"],"layout":"IPY_MODEL_ddec23692f634c34964d1182d2b7c524"}},"aa057e6829ee4b62aa8cd18e233447de":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae5b98d9ad6644588e00034dd8abf9d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc1b6850eb6343f39dc61b2279c337b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b256b58cdbc4cb9afaf9f1cbd6d8c25","placeholder":"​","style":"IPY_MODEL_de9e0fd641a34bf0a9eaa611fdf8afd8","value":" 135556/135556 [00:00&lt;00:00, 199428.36 examples/s]"}},"c6b3426a45484f21bf9b235a59e29e66":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83aa3174cb6f4bcea161a4cc9f23a95c","placeholder":"​","style":"IPY_MODEL_8aaeafb316d04bb3a66e4989c8f4dee0","value":"Downloading data: 100%"}},"c8622fdd4fdc499291dcb173f911b2f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ed96ec59efa41d6988a5373d5668260","max":4028,"min":0,"orientation":"horizontal","style":"IPY_MODEL_30562168fc3c4530b8de144cc7a8dd8f","value":4028}},"c98391c7a6734a9bb3e555d92885ba65":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5cff6ae8b97e4bdd93db766971ba8c91","IPY_MODEL_c8622fdd4fdc499291dcb173f911b2f2","IPY_MODEL_da16f6388eef4b6c85fa170832b53844"],"layout":"IPY_MODEL_dfdc3a8e0b94402893d20ec1beccaa58"}},"cc005186ca8941868db0c688d919c9ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2ec88b9df6947418107d1fae977d025":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da16f6388eef4b6c85fa170832b53844":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa057e6829ee4b62aa8cd18e233447de","placeholder":"​","style":"IPY_MODEL_ae5b98d9ad6644588e00034dd8abf9d9","value":" 4.03k/4.03k [00:00&lt;00:00, 138kB/s]"}},"ddec23692f634c34964d1182d2b7c524":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de9e0fd641a34bf0a9eaa611fdf8afd8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dfdc3a8e0b94402893d20ec1beccaa58":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6df980302c8485e81f4a90c734c697d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9a28d633ee54c26bb76a83de9a6478c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2ec88b9df6947418107d1fae977d025","max":14123673,"min":0,"orientation":"horizontal","style":"IPY_MODEL_11dd7300274a4d2e82e4f28c7f6d00d9","value":14123673}}}}},"nbformat":4,"nbformat_minor":5}
