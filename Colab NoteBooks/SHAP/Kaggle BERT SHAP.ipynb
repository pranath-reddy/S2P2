{"cells":[{"cell_type":"code","execution_count":null,"id":"pRMeb1RXi0Xw","metadata":{"id":"pRMeb1RXi0Xw"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"pRlBaQW9i0cA","metadata":{"id":"pRlBaQW9i0cA"},"outputs":[],"source":["cd drive/My \\Drive/NLP"]},{"cell_type":"code","execution_count":null,"id":"T_xqi3Uo8YMx","metadata":{"id":"T_xqi3Uo8YMx"},"outputs":[],"source":["pip install torch~=2.4.0 torch_xla[tpu]~=2.4.0 -f https://storage.googleapis.com/libtpu-releases/index.html"]},{"cell_type":"code","execution_count":null,"id":"tc1Fh_rKz96-","metadata":{"id":"tc1Fh_rKz96-"},"outputs":[],"source":["!pip install textattack==0.3.7"]},{"cell_type":"code","execution_count":null,"id":"cesQh3Ds29H9","metadata":{"id":"cesQh3Ds29H9"},"outputs":[],"source":["!pip install lime"]},{"cell_type":"code","execution_count":null,"id":"zRwh_Yggvuj2","metadata":{"id":"zRwh_Yggvuj2"},"outputs":[],"source":["!pip install shap"]},{"cell_type":"code","execution_count":null,"id":"86980d01-4250-4b43-b306-6f7587b0edc8","metadata":{"id":"86980d01-4250-4b43-b306-6f7587b0edc8"},"outputs":[],"source":["# Load libraries\n","import nltk\n","import pandas as pd\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n","from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n","from torch.optim import AdamW\n","import torch_xla\n","import torch_xla.core.xla_model as xm\n","import numpy as np\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_recall_fscore_support\n","import random\n","import nltk\n","from lime.lime_text import LimeTextExplainer\n","import numpy as np\n","from lime.lime_text import LimeTextExplainer\n","import torch\n","from transformers import DistilBertTokenizer\n","import random\n","from nltk.corpus import wordnet\n","from transformers import BertTokenizer\n","import shap\n","nltk.download('wordnet')"]},{"cell_type":"code","execution_count":null,"id":"avOpC22wzqtG","metadata":{"id":"avOpC22wzqtG"},"outputs":[],"source":["# Load the dataset\n","df = pd.read_csv('./Data/KaggleData.csv')\n","\n","# Convert to lowercase, remove punctuation, extra spaces, URLs, mentions, and hashtags\n","df['tweet'] = df['tweet'].str.lower().replace(r'[^\\w\\s]', '', regex=True).replace(' {2,}', ' ', regex=True).replace('\"', '')\n","df['tweet'] = df['tweet'].replace(r'http\\S+|www.\\S+|@\\w+|#\\w+', '', regex=True)\n","\n","# Define Dataset class for tokenization and encoding\n","# 0 - hate speech, 1 - offensive language, 2 - neither as positive or negative\n","class TweetDataset(Dataset):\n","    def __init__(self, tweets, labels, tokenizer, max_len):\n","        self.tweets = tweets\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.tweets)\n","\n","    def __getitem__(self, idx):\n","        tweet = str(self.tweets[idx])\n","        label = self.labels[idx]\n","        encoding = self.tokenizer.encode_plus(\n","            tweet,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            return_token_type_ids=False,\n","            padding='max_length',\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","            truncation=True\n","        )\n","        return {\n","            'tweet_text': tweet,\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'labels': torch.tensor(label, dtype=torch.long)\n","        }\n","\n","# Preprocessing\n","tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","MAX_LEN = 128\n","BATCH_SIZE = 32\n","EPOCHS = 5\n","\n","# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(df['tweet'], df['class'], test_size=0.3, stratify=df['class'], random_state=42)\n","\n","# Reset index for train and test DataFrames\n","X_train = X_train.reset_index(drop=True)\n","y_train = y_train.reset_index(drop=True)\n","X_test = X_test.reset_index(drop=True)\n","y_test = y_test.reset_index(drop=True)\n","\n","# Prepare DataLoaders\n","train_dataset = TweetDataset(X_train, y_train, tokenizer, MAX_LEN)\n","test_dataset = TweetDataset(X_test, y_test, tokenizer, MAX_LEN)\n","train_data_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","test_data_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","# Model setup\n","device = xm.xla_device()\n","#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(set(y_train))).to(device)\n","\n","# Optimizer and scheduler\n","optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n","total_steps = len(train_data_loader) * EPOCHS\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n","\n","# Training loop\n","for epoch in range(EPOCHS):\n","    model.train()\n","    epoch_loss = 0\n","    for batch in train_data_loader:\n","          input_ids = batch[\"input_ids\"].to(device)\n","          attention_mask = batch[\"attention_mask\"].to(device)\n","          labels = batch[\"labels\"].to(device)\n","          outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","\n","          loss = outputs.loss\n","          loss.backward()\n","          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","\n","          xm.optimizer_step(optimizer)\n","          scheduler.step()\n","          optimizer.zero_grad()\n","          xm.mark_step()\n","          epoch_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss / len(train_data_loader)}\")\n","\n","    # Save Model\n","    torch.save(model, './Weights/KaggleDistilBERT.pth')\n","\n","model = torch.load('./Weights/KaggleDistilBERT.pth')\n","\n","# Evaluation\n","model.eval()\n","y_pred = []\n","y_true = []\n","\n","with torch.no_grad():\n","    for batch in test_data_loader:\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","\n","        _, preds = torch.max(outputs.logits, dim=1)\n","        y_pred.extend(preds.detach().cpu().numpy().tolist())\n","        y_true.extend(labels.detach().cpu().numpy().tolist())\n","true_labels, predictions = np.asarray(y_true), np.asarray(y_pred)\n","\n","# Calculate accuracy, precision, recall, F1-score, and confusion matrix\n","accuracy = np.mean(np.array(predictions) == np.array(true_labels))\n","precision, recall, f1_score, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n","conf_mat = confusion_matrix(true_labels, predictions)\n","\n","print(\"Accuracy: \", accuracy)\n","print(\"Precision: \", precision)\n","print(\"Recall: \", recall)\n","print(\"F1-score: \", f1_score)\n","print(\"Confusion Matrix:\\n\", conf_mat)"]},{"cell_type":"code","execution_count":null,"id":"eRpwRTLtv2aM","metadata":{"id":"eRpwRTLtv2aM"},"outputs":[],"source":["word2index = {}\n","for tweet in df['tweet']:\n","    for word in tweet:\n","        if word not in word2index:\n","            word2index[word] = len(word2index)\n","\n","# Wrapper for the TextCNN model\n","class BERTWrapper:\n","    def __init__(self, model):\n","        self.model = model\n","\n","    def __call__(self, text_input_list):\n","        preds = []\n","        for text in text_input_list:\n","            input_tensor = tokenize_and_pad([text]).long()\n","            output = self.model(input_tensor.to(device))\n","            pred = torch.softmax(output, dim=1).squeeze().tolist()\n","            preds.append(pred)\n","        return np.array(preds)\n","\n","def tokenize_and_pad(text_list):\n","    max_length = 50\n","    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n","    tokens = [tokenizer.tokenize(text)[:max_length] for text in text_list]\n","    token_indices = np.zeros((len(tokens), max_length), dtype=int)\n","    for i, tweet in enumerate(tokens):\n","        for j, word in enumerate(tweet):\n","            if word in word2index:\n","                token_indices[i, j] = word2index[word]\n","    return torch.tensor(token_indices)\n","\n","wrapped_model = BERTWrapper(model)\n","class_names = ['hate_speech', 'offensive_language', 'neither']\n","\n","# Explainability with SHAP\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","def shap_analysis(text, wrapped_model, class_names):\n","    # Define a masker\n","    masker = shap.maskers.Text(tokenizer)\n","\n","    # Initialize explainer\n","    explainer = shap.Explainer(wrapped_model, masker=masker)\n","\n","    # Explain prediction\n","    shap_values = explainer([text])\n","\n","    return shap_values\n","\n","df['tweet'] = df['tweet'].apply(lambda x: ' '.join(x))\n","text_to_explain = random.choice(df['tweet'])\n","print(\"Text to explain:\", text_to_explain)\n","shap_results = shap_analysis(text_to_explain, wrapped_model, class_names)\n","\n","# Get predicted label for the text\n","predicted_label = np.argmax(wrapped_model([text_to_explain])[0])\n","\n","shap.plots.text(shap_results[0])\n","\n","def calculate_doe(shap_values, predicted_label):\n","    feature_scores = [abs(value) for value in shap_values.values[0][:, predicted_label]]\n","    std_dev = np.std(feature_scores)\n","    significant_features = len([score for score in feature_scores if score > std_dev])\n","    return significant_features / len(feature_scores)\n","\n","doe = calculate_doe(shap_results, predicted_label)\n","print(\"Degree of Explainability (DoE):\", doe)\n","\n","# Define number of samples for analysis\n","num_sam = 20\n","\n","# Load dataset\n","def load_custom_dataset(path):\n","    df = pd.read_csv(path)\n","    df = df.dropna(subset=['tweet', 'class'])\n","    return df\n","\n","# SHAP Analysis\n","def shap_analysis(text, wrapped_model, class_names):\n","    # Define a masker\n","    masker = shap.maskers.Text(tokenizer)\n","\n","    # Initialize explainer\n","    explainer = shap.Explainer(wrapped_model, masker=masker)\n","\n","    # Explain prediction\n","    shap_values = explainer([text])\n","\n","    return shap_values\n","\n","# Calculate Degree of Explainability (DoE)\n","def calculate_doe(shap_values, predicted_label):\n","    feature_scores = [abs(value) for value in shap_values.values[0][:, predicted_label]]\n","    std_dev = np.std(feature_scores)\n","    significant_features = len([score for score in feature_scores if score > std_dev])\n","    return significant_features / len(feature_scores)\n","\n","# Calculate average DoE for multiple samples\n","def calculate_average_doe(df, wrapped_model, class_names, samples=num_sam):\n","    doe_values = []\n","    sample_texts = random.sample(list(df['tweet']), samples)\n","    for text in sample_texts:\n","        shap_results = shap_analysis(text, wrapped_model, class_names)\n","        predicted_label = np.argmax(wrapped_model([text])[0])\n","        doe = calculate_doe(shap_results, predicted_label)\n","        doe_values.append(doe)\n","    average_doe = np.mean(doe_values)\n","    return average_doe\n","\n","# Path to the dataset\n","test_data_path = \"./Data/KaggleData.csv\"\n","df = load_custom_dataset(test_data_path)\n","\n","# Assuming wrapped_model and class_names are defined elsewhere\n","class_names = ['Hate speech', 'Offensive language', 'Neutral']\n","\n","# Calculate and print average DoE\n","average_doe = calculate_average_doe(df, wrapped_model, class_names)\n","print(f\"Average Degree of Explainability (DoE) for {num_sam} samples:\", average_doe)"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":5}
